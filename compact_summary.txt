================================================================================
CDCT BENCHMARK RESULTS - COMPACT SUMMARY
================================================================================

Total Experiments: 56
Models: 7
Domains: 8
Concepts: 8

--------------------------------------------------------------------------------
MODEL RANKINGS (by Mean CSI - lower is better)
--------------------------------------------------------------------------------

Rank   Model                          Mean CSI     Std        N    
--------------------------------------------------------------------------------
1      gpt-5-mini                     0.0949       0.1028     8    
2      grok-4-fast-reasoning          0.1048       0.0952     8    
3      DeepSeek-V3-0324               0.1395       0.1345     8    
4      mistral-medium-2505            0.1610       0.1971     8    
5      Phi-4-mini-instruct            0.1616       0.0542     8    
6      gpt-4.1                        0.1671       0.1259     8    
7      gpt-oss-120b                   0.1774       0.1080     8    

--------------------------------------------------------------------------------
DOMAIN DIFFICULTY (by Mean CSI - higher = harder to compress)
--------------------------------------------------------------------------------

Domain                    Mean CSI     Std        N    
--------------------------------------------------------------------------------
computer_science          0.2640       0.2100     7    
art                       0.2202       0.1238     7    
ethics                    0.1588       0.0802     7    
biology                   0.1185       0.0818     7    
mathematics               0.1105       0.1073     7    
linguistics               0.1016       0.0767     7    
physics                   0.0912       0.0658     7    
logic                     0.0852       0.0597     7    

================================================================================
